{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHoSrGnBfVCaw/swf5znuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EderLara/CuadernosPythonParaML/blob/main/Tutorial_Polars_Elemental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **POLARS - Introducción a Polars**\n",
        "\n",
        "## **¿Qué es Polars?**\n",
        "\n",
        "Polars es una biblioteca de manipulación de DataFrames escrita en Rust (un lenguaje de programación conocido por su seguridad y velocidad) y que utiliza Apache Arrow como su modelo de memoria columnar en segundo plano.\n",
        "\n",
        "Está diseñada desde cero para el procesamiento en paralelo y la optimización de consultas, lo que la hace significativamente más rápida que Pandas en muchas operaciones, especialmente con datasets grandes.\n",
        "\n",
        "## **¿Por qué Polars? (Ventajas y Cuándo Considerarlo)**\n",
        "\n",
        "Si bien Pandas es fantástico, Polars brilla en ciertos escenarios:\n",
        "\n",
        "1. **Rendimiento Superior:**\n",
        "    * **Velocidad:** Al estar construido en Rust y diseñado para el paralelismo (aprovecha múltiples núcleos de tu CPU automáticamente), Polars puede ser órdenes de magnitud más rápido que Pandas para muchas operaciones (filtrado, agrupaciones, joins).\n",
        "    * **Manejo Eficiente de Memoria:** Utiliza Apache Arrow, que es un formato columnar eficiente, y tiene estrategias para minimizar el uso de memoria y las copias de datos.\n",
        "2. **API Expresiva y Moderna:**\n",
        "    * **Encadenamiento de Métodos (Method Chaining):** La sintaxis de Polars se presta muy bien a encadenar operaciones de forma clara y legible.\n",
        "    * **\"Expression API\" (API de Expresiones): **Este es uno de los conceptos más poderosos de Polars. Te permite definir operaciones complejas sobre columnas de una manera muy flexible y optimizable. Veremos esto en detalle.\n",
        "    * **Lazy Evaluation (Evaluación Perezosa):** Por defecto, muchas operaciones en Polars se construyen como un \"plan de consulta\" (modo lazy) y solo se ejecutan cuando es estrictamente necesario (por ejemplo, al llamar a .collect()). Esto permite a Polars optimizar toda la cadena de operaciones antes de la ejecución.\n",
        "\n",
        "3. **Soporte para Out-of-Core (Streaming):** Polars puede procesar datasets que son más grandes que la memoria RAM disponible utilizando su API de scan_* (ej. scan_csv, scan_parquet). En este modo, Polars procesa los datos en trozos (chunks) sin necesidad de cargarlos todos en memoria.\n",
        "4. **Tipado Estricto y Apache Arrow:** El uso de Arrow asegura una gestión de tipos de datos más robusta y eficiente, además de facilitar la interoperabilidad con otros sistemas que también usan Arrow.\n",
        "\n",
        "---\n",
        "\n",
        "## **Similitudes Conceptuales con Pandas:**\n",
        "Si vienes de Pandas, muchos conceptos te resultarán familiares:\n",
        "\n",
        "* **DataFrame:** La estructura tabular principal.\n",
        "* **Series:** Representa una columna individual.\n",
        "* Operaciones como **selección**, **filtrado**, **agrupación**, **joins**, etc., existen en Polars, aunque la sintaxis para lograrlas puede diferir.\n",
        "\n",
        "## **Diferencias Clave con Pandas (a Alto Nivel):**\n",
        "\n",
        "1. **Índices (Indexes):** Polars no tiene un concepto de índice de fila mutable como el de Pandas (ej. `df.loc[]` basado en etiquetas de índice). Las filas se identifican principalmente por su posición entera. Esto simplifica la API en algunos aspectos y la hace más performante, ya que no hay que mantener la sobrecarga de un índice. Las operaciones se centran más en las columnas y sus valores.\n",
        "2. **Mutabilidad:** Polars favorece fuertemente la inmutabilidad. La mayoría de las operaciones devuelven un nuevo DataFrame o Serie, en lugar de modificar el original \"in-place\". Esto ayuda a prevenir efectos secundarios inesperados.\n",
        "3. **Lazy vs. Eager Execution:**\n",
        "    * **Eager (Ansioso):** Las operaciones se ejecutan inmediatamente (como en Pandas por defecto).\n",
        "    * **Lazy (Perezoso):** Las operaciones se registran en un plan y solo se ejecutan cuando se llama a `.collect()`. Esto permite a Polars aplicar optimizaciones al plan completo. El modo lazy es el más potente y recomendado para rendimiento.\n",
        "4. **Sintaxis de Selección y Manipulación:** Aunque los objetivos son los mismos, la forma de seleccionar columnas, filtrar filas y aplicar transformaciones (especialmente con la API de expresiones) es diferente y muy característica de Polars.\n",
        "\n",
        "---\n",
        "## **Instalación e Importación**\n",
        "1. Instalación Básica (instala los componentes comunes):\n",
        "```\n",
        "pip install polars\n",
        "```\n",
        "\n",
        "2. O, si quieres incluir todas las funcionalidades extra (como conectores a diferentes tipos de archivos, etc.):\n",
        "```\n",
        "pip install polars[all]\n",
        "```\n",
        "\n",
        "3. Importación (La convención es importar Polars con el alias pl):\n",
        "```\n",
        "import polars as pl\n",
        "```"
      ],
      "metadata": {
        "id": "Zmp2WbPCGBaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Tabla de Contenido**"
      ],
      "metadata": {
        "id": "E9nQTAqZJukg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creación de Series y DataFrames**\n",
        "\n",
        "## **Creando Series en Polars (`pl.Series`)**\n",
        "\n",
        "Una Serie en Polars es similar a la de Pandas: un array unidimensional de datos.\n",
        "\n",
        "1. **Desde una lista de Python:**"
      ],
      "metadata": {
        "id": "F94jaWVeJvjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "# Creando una Serie desde una lista, especificando el nombre\n",
        "datos_lista_pl = [10, 20, 30, 40, 50]\n",
        "serie_pl_lista = pl.Series(name=\"mis_numeros\", values=datos_lista_pl)\n",
        "print(\"Serie de Polars desde una lista:\")\n",
        "print(serie_pl_lista)\n",
        "print(\"\\nTipo de dato de la Serie:\", serie_pl_lista.dtype)\n",
        "print(\"Nombre de la Serie:\", serie_pl_lista.name)\n",
        "print(\"Longitud de la Serie:\", len(serie_pl_lista)) # o serie_pl_lista.len()\n",
        "\n",
        "\"\"\"\n",
        "# Salida Esperada:\n",
        "\n",
        "Serie de Polars desde una lista:\n",
        "shape: (5,)\n",
        "Series: 'mis_numeros' [i64]\n",
        "[\n",
        "    10\n",
        "    20\n",
        "    30\n",
        "    40\n",
        "    50\n",
        "]\n",
        "\n",
        "Tipo de dato de la Serie: Int64\n",
        "Nombre de la Serie: mis_numeros\n",
        "Longitud de la Serie: 5\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jWqd3dIMKK4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Especificando el tipo de dato (`dtype`):**\n",
        "\n",
        "Polars tiene su propio sistema de tipos de datos (ej. pl.Int32, pl.Float64, pl.Utf8 para strings, pl.Boolean, pl.Date, pl.Datetime)."
      ],
      "metadata": {
        "id": "C3TuODsTKeGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "datos_strings = [\"manzana\", \"banana\", \"pera\"]\n",
        "# Creando una serie de strings (Utf8 es el tipo para texto en Polars)\n",
        "serie_strings = pl.Series(name=\"frutas\", values=datos_strings, dtype=pl.Utf8)\n",
        "print(\"\\nSerie de Polars de strings:\")\n",
        "print(serie_strings)\n",
        "\n",
        "datos_floats = [1.0, 2.5, 3.0]\n",
        "serie_floats = pl.Series(name=\"decimales\", values=datos_floats, dtype=pl.Float32) # especificamos Float32\n",
        "print(\"\\nSerie de Polars de floats (Float32):\")\n",
        "print(serie_floats)"
      ],
      "metadata": {
        "id": "2fxjLGtLNkcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creando DataFrames en Polars (`pl.DataFrame`)**\n",
        "\n",
        "1. **Desde un diccionario de Python (listas, pl.Series, arrays de NumPy):**\n",
        "\n",
        "Esta es la forma más común. Las claves del diccionario son los nombres de las columnas y los valores son los datos de esas columnas."
      ],
      "metadata": {
        "id": "BaoYJDr0Nnr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "\n",
        "datos_df_pl = {\n",
        "    'ID_Producto': [101, 102, 103, 104],\n",
        "    'Nombre_Producto': ['Teclado', 'Mouse', 'Monitor', 'Webcam'],\n",
        "    'Precio': [75.0, 25.5, 300.0, 45.99],\n",
        "    'Stock': np.array([50, 120, 30, 75]) # Podemos usar arrays de NumPy\n",
        "}\n",
        "df_pl = pl.DataFrame(datos_df_pl)\n",
        "print(\"\\nDataFrame de Polars desde un diccionario:\")\n",
        "print(df_pl)\n",
        "print(\"\\nSchema del DataFrame:\") # El schema es como el .info() pero más enfocado en tipos\n",
        "print(df_pl.schema)\n",
        "\n",
        "\"\"\"\n",
        "DataFrame de Polars desde un diccionario:\n",
        "shape: (4, 4)\n",
        "┌─────────────┬─────────────────┬────────┬───────┐\n",
        "│ ID_Producto ┆ Nombre_Producto ┆ Precio ┆ Stock │\n",
        "│ ---         ┆ ---             ┆ ---    ┆ ---   │\n",
        "│ i64         ┆ str             ┆ f64    ┆ i64   │\n",
        "╞═════════════╪═════════════════╪════════╪═══════╡\n",
        "│ 101         ┆ Teclado         ┆ 75.0   ┆ 50    │\n",
        "│ 102         ┆ Mouse           ┆ 25.5   ┆ 120   │\n",
        "│ 103         ┆ Monitor         ┆ 300.0  ┆ 30    │\n",
        "│ 104         ┆ Webcam          ┆ 45.99  ┆ 75    │\n",
        "└─────────────┴─────────────────┴────────┴───────┘\n",
        "\n",
        "Schema del DataFrame:\n",
        "OrderedDict([('ID_Producto', Int64), ('Nombre_Producto', Utf8), ('Precio', Float64), ('Stock', Int64)])\n",
        "\n",
        "Polars también infiere los tipos aquí.\n",
        "La representación visual del DataFrame en la consola es muy útil.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "h5tMNkZZN5RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Definiendo el Schema explícitamente:**\n",
        "\n",
        "Se pueden definir los tipos de datos de cada columna al crear el DataFrame para mayor control o para optimizar."
      ],
      "metadata": {
        "id": "KNo_W-kiOE7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "datos_para_schema = {\n",
        "    'col_a': [1, 2, 3],\n",
        "    'col_b': [True, False, True],\n",
        "    'col_c': ['x', 'y', 'z']\n",
        "}\n",
        "mi_schema = {\n",
        "    'col_a': pl.Int16, # Usamos un entero más pequeño\n",
        "    'col_b': pl.Boolean,\n",
        "    'col_c': pl.Utf8\n",
        "}\n",
        "df_con_schema = pl.DataFrame(data=datos_para_schema, schema=mi_schema)\n",
        "print(\"\\nDataFrame de Polars con schema explícito:\")\n",
        "print(df_con_schema)\n",
        "print(\"\\nSchema resultante:\")\n",
        "print(df_con_schema.schema)"
      ],
      "metadata": {
        "id": "QfALIVWMOwlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Desde una lista de diccionarios (usando pl.from_dicts()):**\n",
        "\n",
        "* Cada diccionario representa una fila.\n",
        "* Polars manejará las claves faltantes introduciendo valores nulos (null en Polars, análogo a NaN en Pandas para números o None para objetos)."
      ],
      "metadata": {
        "id": "ALr2CQ2SO9Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "lista_de_diccionarios_pl = [\n",
        "    {'Nombre': 'Carlos', 'Edad': 25, 'Profesion': 'Ingeniero'},\n",
        "    {'Nombre': 'Laura', 'Edad': 30, 'Profesion': 'Doctora'},\n",
        "    {'Nombre': 'Pedro', 'Edad': 22, 'Ciudad': 'Bogotá'} # Clave 'Ciudad' nueva, 'Profesion' puede faltar\n",
        "]\n",
        "df_desde_lista_dic_pl = pl.from_dicts(lista_de_diccionarios_pl)\n",
        "print(\"\\nDataFrame de Polars desde una lista de diccionarios:\")\n",
        "print(df_desde_lista_dic_pl)\n",
        "print(\"\\nSchema resultante:\")\n",
        "print(df_desde_lista_dic_pl.schema)"
      ],
      "metadata": {
        "id": "rGcqem0LPD6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Leyendo desde archivos (adelanto):**\n",
        "\n",
        "Al igual que Pandas, Polars puede leer de varios formatos. Suelen ser más rápidas y eficientes, especialmente `read_parquet` y `scan_csv` (para modo lazy).\n",
        "\n",
        "```\n",
        "# Conceptualmente (no se ejecutará sin un archivo real):\n",
        "df_csv_polars = pl.read_csv(\"ruta/a/tu/archivo.csv\")\n",
        "df_parquet_polars = pl.read_parquet(\"ruta/a/tu/archivo.parquet\")\n",
        "\n",
        "# Usando scan_csv para modo lazy (se explicará más adelante):\n",
        "df_lazy_csv = pl.scan_csv(\"ruta/a/tu/archivo_grande.csv\")\n",
        "df_resultado = df_lazy_csv.filter(pl.col(\"columna\") > 10).collect()\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cP4db9CIPFfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inspección y Exploración Básica de Datos**\n",
        "\n",
        "Al igual que con Pandas, una vez que tienes un DataFrame en Polars (ya sea creado o cargado), querrás entender su estructura, los tipos de datos que contiene, y obtener una visión general de su contenido. Polars ofrece un conjunto de atributos y métodos muy eficientes para esto.\n",
        "\n",
        "Primero, creemos un DataFrame de Polars para nuestros ejemplos de inspección. Lo haremos similar al que usamos con Pandas para que puedas comparar, pero usando las convenciones de Polars."
      ],
      "metadata": {
        "id": "qJx89pwgPo6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from datetime import date, datetime, timedelta # Para crear fechas y datetimes\n",
        "\n",
        "# Creando un DataFrame de Polars de ejemplo\n",
        "datos_polars_inspeccion = {\n",
        "    'ID_Sensor': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'Tipo_Sensor': ['Temp', 'Hum', 'Pres', 'Temp', 'Luz', 'Hum', 'Temp', None], # String con un None\n",
        "    'Lectura_Valor': [22.5, 65.2, 1012.5, 23.1, 800.0, 66.0, None, 10.5], # Float con un None\n",
        "    'Fecha_Lectura': [\n",
        "        date(2025, 5, 10), date(2025, 5, 10), date(2025, 5, 11), date(2025, 5, 11),\n",
        "        date(2025, 5, 12), date(2025, 5, 12), date(2025, 5, 13), date(2025, 5, 13)\n",
        "    ],\n",
        "    'Hora_Lectura': [\n",
        "        datetime(2025, 5, 10, 10, 0, 0), datetime(2025, 5, 10, 10, 5, 0),\n",
        "        datetime(2025, 5, 11, 14, 30, 0), datetime(2025, 5, 11, 14, 32, 0),\n",
        "        datetime(2025, 5, 12, 8, 0, 0), None, # Datetime con un None\n",
        "        datetime(2025, 5, 13, 18, 0, 0), datetime(2025, 5, 13, 18, 3, 0)\n",
        "    ],\n",
        "    'Activo': [True, True, False, True, True, False, True, False]\n",
        "}\n",
        "\n",
        "# Definimos el schema para mejor control de tipos, especialmente para Date y Datetime\n",
        "schema_definido = {\n",
        "    'ID_Sensor': pl.Int32,\n",
        "    'Tipo_Sensor': pl.Utf8,      # Tipo para strings\n",
        "    'Lectura_Valor': pl.Float32,\n",
        "    'Fecha_Lectura': pl.Date,\n",
        "    'Hora_Lectura': pl.Datetime, # Acepta microsegundos por defecto, podemos especificar 'us' o 'ms'\n",
        "    'Activo': pl.Boolean\n",
        "}\n",
        "\n",
        "df_pl_ins = pl.DataFrame(datos_polars_inspeccion, schema=schema_definido)\n",
        "\n",
        "print(\"DataFrame de Polars para inspección:\")\n",
        "print(df_pl_ins)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "t5LiqporQB6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **`head(n)` y `tail(n)`: Ver las primeras/últimas filas:**\n",
        "Funcionan de manera muy similar a Pandas. Por defecto muestran 5 filas."
      ],
      "metadata": {
        "id": "aMSRTftdQF0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Primeras 3 filas del DataFrame (df_pl_ins.head(3)):\")\n",
        "print(df_pl_ins.head(3))\n",
        "\n",
        "print(\"\\nÚltimas 2 filas del DataFrame (df_pl_ins.tail(2)):\")\n",
        "print(df_pl_ins.tail(2))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "QHVHyeXwQYpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **`shape`: Dimensiones del DataFrame**\n",
        "Un atributo que devuelve una tupla (número_de_filas, número_de_columnas)."
      ],
      "metadata": {
        "id": "qWSIIktxQeH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensiones del DataFrame (filas, columnas) (df_pl_ins.shape):\")\n",
        "print(df_pl_ins.shape)\n",
        "print(f\"El DataFrame tiene {df_pl_ins.shape[0]} filas y {df_pl_ins.shape[1]} columnas.\")\n",
        "\n",
        "# También puedes obtener alto y ancho por separado:\n",
        "print(f\"Altura (número de filas): {df_pl_ins.height}\")\n",
        "print(f\"Anchura (número de columnas): {df_pl_ins.width}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "usfnnxeyQqdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **`describe()`: Estadísticas descriptivas**\n",
        "\n",
        "Proporciona un resumen estadístico de las columnas. Para columnas numéricas, incluye count (no nulos), null_count, mean, std, min, percentiles (25%, 50%, 75%) y max. Para columnas no numéricas (como strings), muestra count, null_count, unique, y mode (el valor más frecuente).\n",
        "\n"
      ],
      "metadata": {
        "id": "O9p1Zm12QtSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Estadísticas descriptivas del DataFrame (df_pl_ins.describe()):\")\n",
        "print(df_pl_ins.describe())\n",
        "# Nota: Polars describe() intenta ser inteligente y puede mostrar diferentes cosas\n",
        "# según el tipo de dato de la columna, incluyendo strings.\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "La salida de describe() en Polars es bastante completa y se adapta bien a diferentes tipos de datos.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lTemzkHVSsG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **`dtypes`: Tipos de datos de cada columna**\n",
        "Un atributo que devuelve una lista de los tipos de datos de Polars para cada columna."
      ],
      "metadata": {
        "id": "qW0Y4COjSvEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tipos de datos de cada columna (df_pl_ins.dtypes):\")\n",
        "print(df_pl_ins.dtypes)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\"\"\"\n",
        "Salida Esperada:\n",
        "\n",
        "[Int32, Utf8, Float32, Date, Datetime(time_unit='us', time_zone=None), Boolean]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "njkzTc4lUMGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. **`schema`: Schema del DataFrame**\n",
        "Un atributo que devuelve un diccionario ordenado (o similar) mapeando los nombres de las columnas a sus tipos de datos de Polars. Es más detallado que dtypes porque muestra los nombres de las columnas junto con los tipos."
      ],
      "metadata": {
        "id": "SoSwh2IDUZIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Schema del DataFrame (df_pl_ins.schema):\")\n",
        "print(df_pl_ins.schema)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\"\"\"\n",
        "Salida Esperada:\n",
        "\n",
        "OrderedDict({'ID_Sensor': Int32, 'Tipo_Sensor': Utf8, 'Lectura_Valor': Float32, 'Fecha_Lectura': Date, 'Hora_Lectura': Datetime(time_unit='us', time_zone=None), 'Activo': Boolean})\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p3FAksBicmIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. **`columns`: Nombres de las columnas:**\n",
        "Un atributo que devuelve una lista con los nombres de todas las columnas."
      ],
      "metadata": {
        "id": "SpMGFmA3NybT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Nombres de las columnas (df_pl_ins.columns):\")\n",
        "print(df_pl_ins.columns)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "MigOI5MSN7n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. **`glimpse()`: Un vistazo rápido al DataFrame:**\n",
        "Este método es específico de Polars y es muy útil. Muestra una vista transpuesta del DataFrame, listando cada columna, su tipo de dato, y los primeros valores. Es como una combinación de info() y head() pero más compacto y orientado a la estructura."
      ],
      "metadata": {
        "id": "KYfAv5kkN8cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vistazo al DataFrame (df_pl_ins.glimpse()):\")\n",
        "df_pl_ins.glimpse() # glimpse() imprime directamente, no devuelve un objeto para imprimir\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\"\"\"\n",
        "  Salida Esperada:\n",
        "\n",
        "Vistazo al DataFrame (df_pl_ins.glimpse()):\n",
        "Rows: 8\n",
        "Columns: 6\n",
        "$ ID_Sensor     <i32> 1, 2, 3, 4, 5, 6, 7, 8\n",
        "$ Tipo_Sensor   <str> 'Temp', 'Hum', 'Pres', 'Temp', 'Luz', 'Hum', 'Temp', None\n",
        "$ Lectura_Valor <f32> 22.5, 65.2, 1012.5, 23.1, 800.0, 66.0, None, 10.5\n",
        "$ Fecha_Lectura <date> 2025-05-10, 2025-05-10, 2025-05-11, 2025-05-11, 2025-05-12, 2025-05-12, 2025-05-13, 2025-05-13\n",
        "$ Hora_Lectura  <datetime[μs]> 2025-05-10 10:00:00, 2025-05-10 10:05:00, 2025-05-11 14:30:00, 2025-05-11 14:32:00, 2025-05-12 08:00:00, None, 2025-05-13 18:00:00, 2025-05-13 18:03:00\n",
        "$ Activo        <bool> true, true, false, true, true, false, true, false\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "31ErNo8rOiKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. **`is_empty()`: Verificar si el DataFrame está vacío**"
      ],
      "metadata": {
        "id": "mLzp8Dj-OuDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"¿El DataFrame está vacío? (df_pl_ins.is_empty()): {df_pl_ins.is_empty()}\")\n",
        "df_vacio = pl.DataFrame()\n",
        "print(f\"¿Un DataFrame vacío lo está? (df_vacio.is_empty()): {df_vacio.is_empty()}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "TfGFhmgqOyRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. **Operaciones en Series: `is_unique()`, `n_unique()`, `value_counts()`**\n",
        "Estas operaciones se aplican a una columna (Serie) del DataFrame."
      ],
      "metadata": {
        "id": "sYvZIN_bO3OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una columna (Serie)\n",
        "col_tipo_sensor = df_pl_ins['Tipo_Sensor']\n",
        "print(f\"Columna 'Tipo_Sensor':\\n{col_tipo_sensor}\")\n",
        "\n",
        "# ¿Son todos los valores en 'Tipo_Sensor' únicos?\n",
        "print(f\"\\n¿Son únicos los valores en 'Tipo_Sensor'? {col_tipo_sensor.is_unique().all()}\") # is_unique() devuelve una serie booleana, .all() la reduce\n",
        "\n",
        "# Número de valores únicos en 'Tipo_Sensor'\n",
        "print(f\"Número de valores únicos en 'Tipo_Sensor': {col_tipo_sensor.n_unique()}\")\n",
        "\n",
        "# Frecuencia de cada valor en 'Tipo_Sensor'\n",
        "print(\"\\nFrecuencia de valores en 'Tipo_Sensor' (value_counts()):\")\n",
        "print(col_tipo_sensor.value_counts())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\"\"\"\n",
        "  Salida Esperada:\n",
        "\n",
        "Frecuencia de valores en 'Tipo_Sensor' (value_counts()):\n",
        "shape: (5, 2)\n",
        "┌─────────────┬────────┐\n",
        "│ Tipo_Sensor ┆ counts │\n",
        "│ ---         ┆ ---    │\n",
        "│ str         ┆ u32    │\n",
        "╞═════════════╪════════╡\n",
        "│ Temp        ┆ 3      │\n",
        "│ Hum         ┆ 2      │\n",
        "│ Luz         ┆ 1      │\n",
        "│ null        ┆ 1      │\n",
        "│ Pres        ┆ 1      │\n",
        "└─────────────┴────────┘\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "IN2OKacgPB51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Selección y Filtrado de Datos**\n",
        "\n",
        "Esta es una de las áreas donde Polars realmente muestra su poder y su enfoque diferente, principalmente a través de su API de Expresiones. Las expresiones te permiten construir operaciones complejas de forma declarativa, que Polars luego puede optimizar, especialmente en modo lazy (aunque también funcionan en modo eager)\n",
        "\n",
        "Seguimos usando el mismo dataset:"
      ],
      "metadata": {
        "id": "CaFIZ1Q7PJyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from datetime import date, datetime # Para nuestros datos de ejemplo\n",
        "\n",
        "# Recreamos el DataFrame anterior para consistencia\n",
        "datos_polars_inspeccion = {\n",
        "    'ID_Sensor': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'Tipo_Sensor': ['Temp', 'Hum', 'Pres', 'Temp', 'Luz', 'Hum', 'Temp', None],\n",
        "    'Lectura_Valor': [22.5, 65.2, 1012.5, 23.1, 800.0, 66.0, None, 10.5],\n",
        "    'Fecha_Lectura': [\n",
        "        date(2025, 5, 10), date(2025, 5, 10), date(2025, 5, 11), date(2025, 5, 11),\n",
        "        date(2025, 5, 12), date(2025, 5, 12), date(2025, 5, 13), date(2025, 5, 13)\n",
        "    ],\n",
        "    'Hora_Lectura': [\n",
        "        datetime(2025, 5, 10, 10, 0, 0), datetime(2025, 5, 10, 10, 5, 0),\n",
        "        datetime(2025, 5, 11, 14, 30, 0), datetime(2025, 5, 11, 14, 32, 0),\n",
        "        datetime(2025, 5, 12, 8, 0, 0), None,\n",
        "        datetime(2025, 5, 13, 18, 0, 0), datetime(2025, 5, 13, 18, 3, 0)\n",
        "    ],\n",
        "    'Activo': [True, True, False, True, True, False, True, False]\n",
        "}\n",
        "schema_definido = {\n",
        "    'ID_Sensor': pl.Int32, 'Tipo_Sensor': pl.Utf8, 'Lectura_Valor': pl.Float32,\n",
        "    'Fecha_Lectura': pl.Date, 'Hora_Lectura': pl.Datetime, 'Activo': pl.Boolean\n",
        "}\n",
        "df_pl_ins = pl.DataFrame(datos_polars_inspeccion, schema=schema_definido)\n",
        "\n",
        "print(\"DataFrame original Selección y Filtrado de Datos:\")\n",
        "print(df_pl_ins)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "54s0ineoPvjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Selección de Columnas**\n",
        "\n",
        "  ### **Usando `df.select()` con Expresiones `pl.col()` (la forma más idiomática y potente):**\n",
        "\n",
        "  El método `select()` es la principal forma de elegir, transformar o crear nuevas columnas. Se usa con expresiones de Polars, comúnmente pl.col(\"nombre_columna\") para referirse a una columna existente."
      ],
      "metadata": {
        "id": "snNANaRARCJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Selección de Columnas con df.select() ---\")\n",
        "# Seleccionar una sola columna\n",
        "df_una_columna = df_pl_ins.select(pl.col(\"Tipo_Sensor\"))\n",
        "print(\"\\nSelección de una columna ('Tipo_Sensor'):\")\n",
        "print(df_una_columna)\n",
        "\n",
        "# Seleccionar múltiples columnas\n",
        "df_multiples_columnas = df_pl_ins.select(\n",
        "    pl.col(\"ID_Sensor\"),\n",
        "    pl.col(\"Fecha_Lectura\"),\n",
        "    pl.col(\"Lectura_Valor\")\n",
        ")\n",
        "print(\"\\nSelección de múltiples columnas:\")\n",
        "print(df_multiples_columnas)\n",
        "\n",
        "# Seleccionar columnas y renombrarlas con alias\n",
        "df_con_alias = df_pl_ins.select(\n",
        "    pl.col(\"ID_Sensor\").alias(\"Identificador\"),\n",
        "    pl.col(\"Lectura_Valor\").alias(\"Valor\")\n",
        ")\n",
        "print(\"\\nSelección con alias:\")\n",
        "print(df_con_alias)\n",
        "\n",
        "# Seleccionar todas las columnas\n",
        "df_todas_columnas = df_pl_ins.select(pl.all()) # pl.all() selecciona todo\n",
        "# print(\"\\nTodas las columnas (igual que el original en este caso):\")\n",
        "# print(df_todas_columnas)\n",
        "\n",
        "# Excluir columnas\n",
        "df_sin_fechas = df_pl_ins.select(pl.all().exclude(\"Fecha_Lectura\", \"Hora_Lectura\"))\n",
        "print(\"\\nTodas las columnas EXCEPTO las de fecha:\")\n",
        "print(df_sin_fechas)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "Xb1aS0RZRj2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Usando `df.select()` con strings o listas de strings (más conciso para selección simple):**\n",
        "Polars permite pasar directamente strings o listas de strings a select para una selección simple."
      ],
      "metadata": {
        "id": "MsSeOExbSjBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una columna pasando su nombre como string\n",
        "df_tipo_sensor_str = df_pl_ins.select(\"Tipo_Sensor\")\n",
        "print(\"Selección de 'Tipo_Sensor' usando string:\")\n",
        "print(df_tipo_sensor_str)\n",
        "\n",
        "# Seleccionar múltiples columnas pasando una lista de strings\n",
        "df_id_valor_str = df_pl_ins.select([\"ID_Sensor\", \"Lectura_Valor\", \"Activo\"])\n",
        "print(\"\\nSelección de múltiples columnas usando lista de strings:\")\n",
        "print(df_id_valor_str)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "HSpCaHzmSiQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Usando Selectores (API `pl.selectors` o cs):**\n",
        "Para selecciones más programáticas o basadas en patrones/tipos."
      ],
      "metadata": {
        "id": "SeYn16koTEoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars.selectors as cs # Alias común para los selectores\n",
        "\n",
        "# Seleccionar todas las columnas de tipo string (Utf8)\n",
        "df_columnas_string = df_pl_ins.select(cs.string()) # cs.string() es un alias para cs.by_dtype(pl.Utf8)\n",
        "print(\"Selección de todas las columnas de tipo string (Utf8):\")\n",
        "print(df_columnas_string)\n",
        "\n",
        "# Seleccionar todas las columnas numéricas (enteros y flotantes)\n",
        "df_columnas_numericas = df_pl_ins.select(cs.numeric())\n",
        "print(\"\\nSelección de todas las columnas numéricas:\")\n",
        "print(df_columnas_numericas)\n",
        "\n",
        "# Seleccionar columnas que empiezan con \"Fecha_\"\n",
        "df_columnas_fecha = df_pl_ins.select(cs.starts_with(\"Fecha_\"))\n",
        "print(\"\\nSelección de columnas que empiezan con 'Fecha_':\")\n",
        "print(df_columnas_fecha)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "JCm6SS2tTJkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Acceso directo con corchetes [ ] (similar a Pandas):**\n",
        "\n",
        "* `df[\"nombre_columna\"]` devuelve una Serie de Polars.\n",
        "* `df[[\"col1\", \"col2\"]]` devuelve un DataFrame de Polars con esas columnas."
      ],
      "metadata": {
        "id": "7QF5_zndTX6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar una columna como Serie\n",
        "serie_tipo_sensor = df_pl_ins[\"Tipo_Sensor\"]\n",
        "print(\"Columna 'Tipo_Sensor' como Serie de Polars:\")\n",
        "print(serie_tipo_sensor)\n",
        "print(f\"Tipo: {type(serie_tipo_sensor)}\")\n",
        "\n",
        "# Seleccionar múltiples columnas como DataFrame\n",
        "df_id_y_activo = df_pl_ins[[\"ID_Sensor\", \"Activo\"]]\n",
        "print(\"\\nColumnas 'ID_Sensor' y 'Activo' como DataFrame:\")\n",
        "print(df_id_y_activo)\n",
        "print(f\"Tipo: {type(df_id_y_activo)}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "v7OjSuIaTlK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Selección de Filas (Slicing)**\n",
        "\n",
        "Polars no tiene un índice como el de Pandas que se use con .loc o .iloc de la misma manera para la selección de filas basada en etiquetas. La selección de filas se hace principalmente por posición o condición.\n",
        "\n",
        "### **Usando d`f.slice(offset, length)`:**\n",
        "Selecciona un trozo del DataFrame especificando un desplazamiento (desde dónde empezar) y una longitud (cuántas filas tomar).\n",
        "\n",
        "\n",
        "\n",
        "> **Nota:** Recuerda que `df.head(n)` y `df.tail(n)` también son formas de seleccionar las primeras o últimas n filas.\n",
        "\n"
      ],
      "metadata": {
        "id": "zQeIYWNLTqmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Selección de Filas (Slicing) ---\")\n",
        "# Seleccionar 3 filas empezando desde la fila en posición 2 (la tercera fila)\n",
        "df_slice = df_pl_ins.slice(offset=2, length=3)\n",
        "print(\"\\nSlice de 3 filas desde la posición 2:\")\n",
        "print(df_slice)\n",
        "\n",
        "# Seleccionar las primeras 4 filas (similar a head(4) pero con slice)\n",
        "df_slice_inicio = df_pl_ins.slice(offset=0, length=4)\n",
        "# print(\"\\nSlice de las primeras 4 filas:\")\n",
        "# print(df_slice_inicio)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "-ef89SeQT228"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Acceso directo a filas por índice entero (similar a iloc para una sola fila en Pandas):**\n",
        "\n",
        "* `df[indice_fila] `devuelve la fila como un DataFrame de una fila.\n",
        "* `df[indice_inicio:indice_fin]` realiza un slicing."
      ],
      "metadata": {
        "id": "B4sBS7xoUJ96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar la fila en la posición 0 (la primera fila)\n",
        "fila_0 = df_pl_ins[0]\n",
        "print(\"Fila en posición 0:\")\n",
        "print(fila_0)\n",
        "\n",
        "# Slicing de filas (similar a Python, el final es exclusivo)\n",
        "slice_filas_directo = df_pl_ins[2:5] # Filas en posición 2, 3, 4\n",
        "print(\"\\nSlice de filas [2:5]:\")\n",
        "print(slice_filas_directo)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "mjk0yNldU95d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Filtrado de Filas con `df.filter()` y Expresiones**\n",
        "\n",
        "Este es el método principal y más potente para seleccionar filas que cumplen ciertas condiciones. Se usa con la API de Expresiones de Polars."
      ],
      "metadata": {
        "id": "lPps68w2U-05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Filtrado de Filas con df.filter() ---\")\n",
        "# 1. Condición numérica: Sensores con Lectura_Valor > 50.0\n",
        "df_lecturas_altas = df_pl_ins.filter(pl.col(\"Lectura_Valor\") > 50.0)\n",
        "print(\"\\nSensores con Lectura_Valor > 50.0:\")\n",
        "print(df_lecturas_altas)\n",
        "\n",
        "# 2. Condición de string: Sensores de tipo 'Temp'\n",
        "df_tipo_temp = df_pl_ins.filter(pl.col(\"Tipo_Sensor\") == \"Temp\")\n",
        "print(\"\\nSensores de tipo 'Temp':\")\n",
        "print(df_tipo_temp)\n",
        "\n",
        "# También puedes usar métodos de string dentro de las expresiones\n",
        "df_tipo_contiene_m = df_pl_ins.filter(pl.col(\"Tipo_Sensor\").str.contains(\"m\")) # Contiene 'm' (Hum)\n",
        "print(\"\\nSensores cuyo tipo contiene la letra 'm':\")\n",
        "print(df_tipo_contiene_m)\n",
        "\n",
        "# 3. Combinar múltiples condiciones (usando & para AND, | para OR, ~ para NOT):\n",
        "# Sensores de tipo 'Temp' Y que estén 'Activo'\n",
        "df_temp_activos = df_pl_ins.filter(\n",
        "    (pl.col(\"Tipo_Sensor\") == \"Temp\") & (pl.col(\"Activo\") == True) # o simplemente pl.col(\"Activo\")\n",
        ")\n",
        "print(\"\\nSensores de tipo 'Temp' Y Activos:\")\n",
        "print(df_temp_activos)\n",
        "\n",
        "# Sensores con Lectura_Valor < 20 O Lectura_Valor > 500\n",
        "df_lecturas_extremos = df_pl_ins.filter(\n",
        "    (pl.col(\"Lectura_Valor\") < 20.0) | (pl.col(\"Lectura_Valor\") > 500.0)\n",
        ")\n",
        "print(\"\\nSensores con Lectura_Valor < 20.0 O > 500.0:\")\n",
        "print(df_lecturas_extremos)\n",
        "\n",
        "# 4. Usando `.is_in()`:\n",
        "# Sensores de tipo 'Hum' o 'Luz'\n",
        "tipos_buscados = [\"Hum\", \"Luz\"]\n",
        "df_hum_o_luz = df_pl_ins.filter(pl.col(\"Tipo_Sensor\").is_in(tipos_buscados))\n",
        "print(\"\\nSensores de tipo 'Hum' o 'Luz':\")\n",
        "print(df_hum_o_luz)\n",
        "\n",
        "# 5. Usando `.is_null()` o `.is_not_null()`:\n",
        "# Filas donde 'Lectura_Valor' es nulo\n",
        "df_lectura_nula = df_pl_ins.filter(pl.col(\"Lectura_Valor\").is_null())\n",
        "print(\"\\nFilas con 'Lectura_Valor' nulo:\")\n",
        "print(df_lectura_nula)\n",
        "\n",
        "# Filas donde 'Tipo_Sensor' NO es nulo\n",
        "df_tipo_no_nulo = df_pl_ins.filter(pl.col(\"Tipo_Sensor\").is_not_null())\n",
        "print(\"\\nFilas con 'Tipo_Sensor' NO nulo:\")\n",
        "print(df_tipo_no_nulo)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "CMGSxBkGVKXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **Encadenamiento de Operaciones (Selección y Filtrado)**\n",
        "\n",
        "Una gran ventaja de Polars es cómo se pueden encadenar las operaciones de forma legible:"
      ],
      "metadata": {
        "id": "mo1aQ5j3VLnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Encadenamiento de Operaciones ---\")\n",
        "# Seleccionar ID_Sensor, Tipo_Sensor y Lectura_Valor para los sensores 'Temp' que estén activos\n",
        "# y cuya lectura sea mayor a 23.0\n",
        "resultado_encadenado = (\n",
        "    df_pl_ins\n",
        "    .filter(\n",
        "        (pl.col(\"Tipo_Sensor\") == \"Temp\") &\n",
        "        (pl.col(\"Activo\") == True) &\n",
        "        (pl.col(\"Lectura_Valor\") > 23.0)\n",
        "    )\n",
        "    .select([\"ID_Sensor\", \"Tipo_Sensor\", \"Lectura_Valor\"])\n",
        "    .sort(\"Lectura_Valor\", descending=True) # Añadimos un ordenamiento también\n",
        ")\n",
        "print(\"\\nResultado de filtrar y seleccionar encadenadamente:\")\n",
        "print(resultado_encadenado)"
      ],
      "metadata": {
        "id": "riBITwCeVXMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Manipulación de Datos.**\n",
        "\n",
        "Aquí es donde la \"Expression API\" de Polars realmente se luce. La mayoría de las transformaciones, creación de nuevas columnas y modificaciones se realizan de manera muy eficiente y expresiva usando el método `with_columns()` (o a` veces select()` si solo quieres un subconjunto transformado).\n",
        "\n",
        "* DataFrame para ejemplos de manipulación:"
      ],
      "metadata": {
        "id": "L9npR_SuVYA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from datetime import date, datetime, timedelta\n",
        "import numpy as np # Para algún NaN si es necesario\n",
        "\n",
        "# DataFrame de Polars para manipulación\n",
        "datos_manipulacion = {\n",
        "    'ID_Transaccion': range(1, 9),\n",
        "    'Producto': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B'],\n",
        "    'Fecha': [\n",
        "        date(2025, 1, 5), date(2025, 1, 5), date(2025, 1, 6), date(2025, 1, 6),\n",
        "        date(2025, 1, 7), date(2025, 1, 8), date(2025, 1, 8), date(2025, 1, 9)\n",
        "    ],\n",
        "    'Cantidad': [10, 5, 8, 12, 6, 15, 7, 9],\n",
        "    'Precio_Unitario': [100.0, 250.5, 105.0, 50.0, 260.0, None, 52.5, 240.0],   # Incluimos un None\n",
        "    'Descuento_Aplicado': [0.1, 0.0, 0.1, 0.05, 0.0, 0.15, 0.0, 0.05]\n",
        "}\n",
        "schema_manip = {\n",
        "    'ID_Transaccion': pl.Int16, 'Producto': pl.Categorical,                     # Usamos Categorical para Producto\n",
        "    'Fecha': pl.Date, 'Cantidad': pl.Int32, 'Precio_Unitario': pl.Float64,\n",
        "    'Descuento_Aplicado': pl.Float32\n",
        "}\n",
        "df_pl_manip = pl.DataFrame(datos_manipulacion, schema=schema_manip)\n",
        "\n",
        "\"\"\"\n",
        "  Usamos pl.Categorical para la columna 'Producto', que es un tipo de dato eficiente en Polars para strings con un número limitado de valores únicos.\n",
        "\"\"\"\n",
        "\n",
        "print(\"DataFrame original para Manipulación de Datos:\")\n",
        "print(df_pl_manip)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "lt3KZaxzWtU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Añadir y Modificar Columnas con `df.with_columns()`**\n",
        "\n",
        "`with_columns()` es el método principal para añadir nuevas columnas o transformar las existentes. Toma una o más expresiones de Polars.\n",
        "\n",
        " * Añadir una columna con un valor literal (escalar):\n",
        "  Usamos `pl.lit()` para crear una expresión a partir de un valor literal."
      ],
      "metadata": {
        "id": "hrAcEtWTZQ_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_con_literal = df_pl_manip.with_columns(\n",
        "    pl.lit(\"Tienda_Online\").alias(\"Canal_Venta\")\n",
        ")\n",
        "print(\"--- Añadir/Modificar Columnas con with_columns ---\")\n",
        "print(\"\\nDataFrame con nueva columna 'Canal_Venta' (literal):\")\n",
        "print(df_con_literal)"
      ],
      "metadata": {
        "id": "Ia3ZiZZD0fin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Añadir una columna derivada de otras existentes:**"
      ],
      "metadata": {
        "id": "GO4p-CgU0ddz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular Ingreso_Bruto = Cantidad * Precio_Unitario\n",
        "# Calcular Precio_Neto = Precio_Unitario * (1 - Descuento_Aplicado)\n",
        "df_con_calculos = df_pl_manip.with_columns([\n",
        "    (pl.col(\"Cantidad\") * pl.col(\"Precio_Unitario\")).alias(\"Ingreso_Bruto\"),\n",
        "    (pl.col(\"Precio_Unitario\") * (1 - pl.col(\"Descuento_Aplicado\"))).alias(\"Precio_Neto_Unitario\") # Observa que si 'Precio_Unitario' es nulo, el resultado de las operaciones también será nulo.\n",
        "])\n",
        "print(\"\\nDataFrame con 'Ingreso_Bruto' y 'Precio_Neto_Unitario':\")\n",
        "print(df_con_calculos)"
      ],
      "metadata": {
        "id": "fdmzXDQ_0ov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Modificar una columna existente:**\n",
        "Si el alias (`.alias(\"nombre_columna\")`) coincide con el nombre de una columna existente, esa columna se sobrescribe."
      ],
      "metadata": {
        "id": "h_KQkQsU0ptH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir 'Producto' a minúsculas (ya es Categorical, pero .str funciona en expresiones)\n",
        "df_producto_minusculas = df_pl_manip.with_columns(\n",
        "    pl.col(\"Producto\").str.to_lowercase().alias(\"Producto\") # Sobrescribe 'Producto'\n",
        ")\n",
        "print(\"\\nDataFrame con 'Producto' en minúsculas:\")\n",
        "print(df_producto_minusculas)"
      ],
      "metadata": {
        "id": "tpdAdwZaKEPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. **Crear columnas con lógica condicional (`pl.when().then().otherwise()`):**"
      ],
      "metadata": {
        "id": "djjQQzbFKoBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorizar Descuento: 'Alto' si > 0.1, 'Medio' si > 0.05, 'Bajo' de lo contrario\n",
        "df_con_categoria_descuento = df_pl_manip.with_columns(\n",
        "    pl.when(pl.col(\"Descuento_Aplicado\") > 0.1)\n",
        "    .then(pl.lit(\"Alto\"))\n",
        "    .when(pl.col(\"Descuento_Aplicado\") > 0.05)\n",
        "    .then(pl.lit(\"Medio\"))\n",
        "    .otherwise(pl.lit(\"Bajo\"))\n",
        "    .alias(\"Nivel_Descuento\")\n",
        ")\n",
        "print(\"\\nDataFrame con 'Nivel_Descuento':\")\n",
        "print(df_con_categoria_descuento[[\"Producto\", \"Descuento_Aplicado\", \"Nivel_Descuento\"]])\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "7dMmc7eAK1kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Eliminar Columnas con `df.drop()`**"
      ],
      "metadata": {
        "id": "xtTu29K7K2ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Eliminar Columnas ---\")\n",
        "# Creamos una copia para no afectar el df original de esta sección\n",
        "df_para_drop = df_con_calculos.clone() # .clone() para una copia profunda\n",
        "\n",
        "# Eliminar una sola columna\n",
        "df_drop_una = df_para_drop.drop(\"Ingreso_Bruto\")\n",
        "print(\"\\nDataFrame después de eliminar 'Ingreso_Bruto':\")\n",
        "print(df_drop_una.columns)\n",
        "\n",
        "# Eliminar múltiples columnas\n",
        "df_drop_multiples = df_para_drop.drop([\"Ingreso_Bruto\", \"Precio_Neto_Unitario\"])\n",
        "print(\"\\nDataFrame después de eliminar 'Ingreso_Bruto' y 'Precio_Neto_Unitario':\")\n",
        "print(df_drop_multiples.columns)\n",
        "\n",
        "# También se puede pasar una sola columna sin lista a drop\n",
        "# df_drop_una_alt = df_para_drop.drop(\"Ingreso_Bruto\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "hg0xTDuyLIp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **C. Manejo de Valores Nulos (null)**\n",
        "\n",
        "## 1. **Contar nulos (repaso):**"
      ],
      "metadata": {
        "id": "k6hTIQrfLLLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Manejo de Valores Nulos ---\")\n",
        "print(\"Conteo de nulos por columna:\")\n",
        "print(df_pl_manip.null_count()) # Muestra un DataFrame con los conteos\n",
        "# O para una columna específica, dentro de una expresión:\n",
        "# print(df_pl_manip.select(pl.col(\"Precio_Unitario\").is_null().sum().alias(\"nulos_precio\")))"
      ],
      "metadata": {
        "id": "rJfnOzdHLaKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Eliminar filas con nulos: `df.drop_nulls()`:**"
      ],
      "metadata": {
        "id": "Jvf7qHPPMC6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar cualquier fila que tenga al menos un valor nulo\n",
        "df_sin_nulos_filas = df_pl_manip.drop_nulls()\n",
        "print(\"\\nDataFrame después de drop_nulls() (elimina filas con cualquier nulo):\")\n",
        "print(df_sin_nulos_filas) # La fila con Precio_Unitario nulo desaparece\n",
        "\n",
        "# Eliminar filas si tienen nulos en un subconjunto de columnas\n",
        "# (En nuestro df, solo Precio_Unitario tiene nulos)\n",
        "df_sin_nulos_subset = df_pl_manip.drop_nulls(subset=[\"Precio_Unitario\"])\n",
        "print(\"\\nDataFrame después de drop_nulls(subset=['Precio_Unitario']):\")\n",
        "print(df_sin_nulos_subset)"
      ],
      "metadata": {
        "id": "NRfXCnZGMJuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. **Rellenar nulos usando expresiones con fill_null() (dentro de with_columns o select):**\n",
        "\n",
        "* Tambien existen otras estrategías para fill_null: '`backward`', '`min`', '`max`', '`one`', '`zero`'."
      ],
      "metadata": {
        "id": "ivqO15EhSBU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rellenar nulos en 'Precio_Unitario' con un valor literal (ej. 0.0)\n",
        "df_relleno_literal = df_pl_manip.with_columns(\n",
        "    pl.col(\"Precio_Unitario\").fill_null(0.0).alias(\"Precio_Rellenado_Literal\")\n",
        ")\n",
        "print(\"\\n'Precio_Unitario' con nulos rellenados con 0.0:\")\n",
        "print(df_relleno_literal[[\"Precio_Unitario\", \"Precio_Rellenado_Literal\"]])\n",
        "\n",
        "# Rellenar nulos con la media de la columna (Polars calcula la media ignorando nulos)\n",
        "df_relleno_media = df_pl_manip.with_columns(\n",
        "    pl.col(\"Precio_Unitario\").fill_null(pl.col(\"Precio_Unitario\").mean()).alias(\"Precio_Rellenado_Media\")\n",
        ")\n",
        "print(\"\\n'Precio_Unitario' con nulos rellenados con la media:\")\n",
        "print(df_relleno_media[[\"ID_Transaccion\", \"Precio_Unitario\", \"Precio_Rellenado_Media\"]])\n",
        "\n",
        "# Rellenar nulos con una estrategia (ej. 'forward' fill - ffill)\n",
        "# Ordenamos por fecha primero para que el forward fill tenga más sentido si hubiera múltiples nulos\n",
        "df_relleno_forward = df_pl_manip.sort(\"Fecha\").with_columns(\n",
        "    pl.col(\"Precio_Unitario\").fill_null(strategy=\"forward\").alias(\"Precio_Rellenado_Forward\")\n",
        ")\n",
        "print(\"\\n'Precio_Unitario' con nulos rellenados con estrategia 'forward' (después de ordenar):\")\n",
        "print(df_relleno_forward[[\"ID_Transaccion\", \"Fecha\", \"Precio_Unitario\", \"Precio_Rellenado_Forward\"]])\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "76MFmW5_SLF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Renombrar Columnas con `df.rename()`:**"
      ],
      "metadata": {
        "id": "FDHNK79ISRPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Renombrar Columnas ---\")\n",
        "df_renombrado = df_pl_manip.rename({\n",
        "    \"ID_Transaccion\": \"ID\",\n",
        "    \"Precio_Unitario\": \"Precio_Base\"\n",
        "})\n",
        "print(\"\\nDataFrame con columnas renombradas:\")\n",
        "print(df_renombrado.columns)\n",
        "print(df_renombrado.head(2))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "uu0eVFFdSxo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cambiar Tipos de Datos (Casting) con `cast()`**:\n",
        "Se usa como una expresión dentro de `with_columns` o `select`."
      ],
      "metadata": {
        "id": "faPHcBR4S19i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Cambiar Tipos de Datos (Casting) ---\")\n",
        "# Cambiar Cantidad a Float32 y Precio_Unitario (después de rellenar nulos) a Int32\n",
        "df_tipos_cambiados = df_pl_manip.with_columns([\n",
        "    pl.col(\"Cantidad\").cast(pl.Float32),\n",
        "    pl.col(\"Precio_Unitario\").fill_null(0).cast(pl.Int32).alias(\"Precio_Entero_NoNulo\") # Encadenamos fill_null y cast\n",
        "])\n",
        "print(\"\\nDataFrame con tipos de datos cambiados:\")\n",
        "print(df_tipos_cambiados.select([\"Producto\", \"Cantidad\", \"Precio_Entero_NoNulo\"]))\n",
        "print(df_tipos_cambiados.dtypes) # Mostrar los nuevos tipos\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "Sy9c7fHYTC5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ordenar Datos con `df.sort()`**"
      ],
      "metadata": {
        "id": "qFOUrPQjTKjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Ordenar Datos ---\")\n",
        "# Ordenar por 'Fecha' (ascendente) y luego por 'Precio_Unitario' (descendente)\n",
        "df_ordenado = df_pl_manip.sort([\"Fecha\", \"Precio_Unitario\"], descending=[False, True])\n",
        "print(\"\\nDataFrame ordenado por Fecha (asc) y Precio_Unitario (desc):\")\n",
        "print(df_ordenado)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "x8LAmpIYTQqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Aplicar Funciones Personalizadas con map_elements() (en Series/Expresiones):**\n",
        "\n",
        "Si necesitas aplicar una función Python arbitraria que no tiene un equivalente directo en las expresiones de Polars, puedes usar `map_elements()`. Ten en cuenta que esto puede ser más lento que usar expresiones nativas de Polars porque implica pasar datos entre el motor de Rust y el intérprete de Python para cada elemento.\n",
        "\n",
        "> **Nota:** `map_elements` reemplazó a `.apply()` para Series en versiones más recientes de Polars para este tipo de operación. Asegúrate de usar return_dtype."
      ],
      "metadata": {
        "id": "jXCsIt9DUGXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Aplicar Funciones Personalizadas con map_elements ---\")\n",
        "def mi_funcion_compleja_producto(nombre_producto: str) -> str:\n",
        "    if nombre_producto is None:\n",
        "        return \"PRODUCTO DESCONOCIDO\"\n",
        "    return f\"PROD-{nombre_producto.upper()}-XYZ\"\n",
        "\n",
        "# Es crucial especificar el return_dtype para map_elements\n",
        "df_con_map = df_pl_manip.with_columns(\n",
        "    pl.col(\"Producto\")\n",
        "    .map_elements(mi_funcion_compleja_producto, return_dtype=pl.Utf8)\n",
        "    .alias(\"Producto_Transformado\")\n",
        ")\n",
        "print(\"\\nDataFrame con 'Producto_Transformado' usando map_elements:\")\n",
        "print(df_con_map.select([\"Producto\", \"Producto_Transformado\"]))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "p9zVz7cUW27p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **5. Agrupación de Datos (`group_by`) y Agregaciones.**\n",
        "\n",
        "Al igual que en Pandas, la agrupación te permite dividir tus datos en subconjuntos basados en los valores de ciertas columnas y luego realizar cálculos o aplicar transformaciones a cada uno de estos subconjuntos. El paradigma sigue siendo Split-Apply-Combine.\n",
        "\n",
        "En Polars, esto se logra principalmente con el método group_by() seguido del **`método agg()`**, donde la API de Expresiones juega un papel central para definir las agregaciones."
      ],
      "metadata": {
        "id": "fw7LpFz-W4KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "from datetime import date\n",
        "\n",
        "# DataFrame de Polars para agrupación y agregaciones\n",
        "datos_agrupacion = {\n",
        "    'ID_Transaccion': range(1, 11),\n",
        "    'Producto': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'B'],\n",
        "    'Region': ['Norte', 'Sur', 'Norte', 'Este', 'Sur', 'Norte', 'Este', 'Sur', 'Oeste', 'Norte'],\n",
        "    'Fecha': [\n",
        "        date(2025, 1, 5), date(2025, 1, 5), date(2025, 1, 6), date(2025, 1, 6),\n",
        "        date(2025, 1, 7), date(2025, 1, 8), date(2025, 1, 8), date(2025, 1, 9),\n",
        "        date(2025, 1, 9), date(2025, 1, 10)\n",
        "    ],\n",
        "    'Cantidad': [10, 5, 8, 12, 6, 15, 7, 9, 20, 11],\n",
        "    'Ingresos': [1000.0, 1252.5, 840.0, 600.0, 1560.0, 1575.0, 367.5, 2160.0, 2000.0, 2761.0],\n",
        "    'Valoracion': [4, 5, 3, 4, 5, 2, 3, 5, 4, 5]\n",
        "}\n",
        "schema_agrup = {\n",
        "    'ID_Transaccion': pl.Int16, 'Producto': pl.Categorical, 'Region': pl.Categorical,\n",
        "    'Fecha': pl.Date, 'Cantidad': pl.Int32, 'Ingresos': pl.Float64,\n",
        "    'Valoracion': pl.Int8\n",
        "}\n",
        "df_pl_agrup = pl.DataFrame(datos_agrupacion, schema=schema_agrup)\n",
        "\n",
        "print(\"DataFrame original para aprupación de datos:\")\n",
        "print(df_pl_agrup)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "mv021sEAX1qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Usando `df.group_by()`:**\n",
        "\n",
        "El método `group_by()` por sí solo crea un objeto GroupBy. Para obtener un resultado tangible, necesitas encadenarle un método de agregación, típicamente `agg()`.\n",
        "\n",
        "Agrupar por una sola columna:"
      ],
      "metadata": {
        "id": "08R8Jg8tZuFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Agrupación con df.group_by() ---\")\n",
        "# Agrupar por 'Producto'. Esto crea un objeto GroupBy.\n",
        "gb_producto = df_pl_agrup.group_by(\"Producto\")\n",
        "print(\"Tipo de objeto después de group_by:\", type(gb_producto))\n",
        "# <class 'polars.dataframe.group_by.GroupBy'>"
      ],
      "metadata": {
        "id": "JpJZw8h3Z78-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Agrupar por múltiples columnas:**\n",
        "Pasando una lista de nombres de columnas."
      ],
      "metadata": {
        "id": "5f5a6ZsHZ_ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_producto_region = df_pl_agrup.group_by([\"Producto\", \"Region\"])\n",
        "# print(\"\\nTipo de objeto después de group_by múltiple:\", type(gb_producto_region))"
      ],
      "metadata": {
        "id": "JMHVZiRnaEU9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}